%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter4.tex
%% NOVA thesis document file
%%
%% Chapter 4 — Implementation
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter4.tex}%

\chapter{Implementation}
\label{cha:Implementation}

This chapter details the project's implementation. We document the concrete design, the pivots from the initial proposal, and the design choices that led to the final configuration. Quantitative validation and ablation results are reported in Chapter~\ref{cha:Evaluation}. The pipeline runs end-to-end and produces interpretable anomaly flags suitable for routine laboratory use.

\paragraph{Name and Rationale.}
We named the system \textsc{Prometheus} to reflect its purpose and ethos. In Greek myth, Prometheus (Προμηθεύς, “forethought”) brings fire, knowledge and capability to humans, while accepting responsibility for its use. Analogously, \textsc{Prometheus} brings computational “fire” (automation, pattern discovery, and early warnings) into a life-science workflow, with forethought as a design principle: plate-local modeling to avoid leakage, conservative rules to prevent brittle decisions, and human-in-the-loop review for safety. 

\section{Design Evolution at a Glance}
\label{sec:impl_evolution}
Three constraints drove the change from the proposal (DBSCAN + Random Forest) to the final pipeline:
\begin{enumerate}
  \item \textbf{Plate locality.} Anomalies are defined \emph{within} each 96-well plate (comparisons to sibling wells).
  \item \textbf{Order sensitivity.} Base order matters (e.g., single-base mismatches), so we need a sequence model rather than bag-of-$k$-mers alone.
  \item \textbf{Label scarcity.} Very few confirmed anomalies; we must lean on unsupervised/weakly-supervised signals plus interpretable rules.
\end{enumerate}
Consequently, \textsc{Prometheus} adopts a \emph{per-plate} Conv1D autoencoder (AE) to learn plate-specific normal patterns and extract latent features; a supervised gradient-boosting classifier (LightGBM) with plate-wise cross-validation; and a post-hoc rule layer. Plate-local sequence similarity at $\geq 66\%$ identity (BLAST-like) supplies contamination-style features and rule checks.

\section{Co-Design with the Laboratory (Requirements Drift)}
\label{sec:codesign}
The project evolved through continuous discussions with STAB VIDA’s biotechnology team. Several operational realities surfaced after the proposal and materially influenced the design:
\begin{itemize}
  \item \textbf{Direction metadata (forward/reverse).} No reliable field exists in routine exports; the team often infers direction from context or ad-hoc tags (``F''/``R'') that are inconsistently present. We therefore \emph{do not model direction as a feature}. Reverse-complement checks are applied \emph{only when} a reliable pairing is available; otherwise they are omitted to avoid false positives.
  \item \textbf{Naming variability.} \texttt{DNA\_ID} and \texttt{Primer\_ID} are user-entered and may be subjective or inconsistent (synonyms, typos, multiple conventions). To prevent shortcut learning and cross-plate leakage, these identifiers are excluded from the classifier (kept for explanations and rules only).
  \item \textbf{Privacy \& identifiers.} Client names are replaced by pseudonymous \texttt{Client\_ID}s. This reduces identifiable information and aligns with the lab’s confidentiality requirements.
\end{itemize}
These realities transformed the thesis from a straightforward ``build the planned system'' into an \emph{investigation} that bridged domain knowledge and robust ML/software engineering choices.

\section{Data Access \& Collection}
\label{sec:impl_backend_access}

Although the sequencing run produces multiple file types per well (\texttt{.ab1}, \texttt{.seq}, \texttt{.phd.1}, \texttt{.qual}, \texttt{.qualtrace}, etc.), these do not arrive as a single joined artifact by default. Operationally, STAB VIDA maintains a backend with several internal pages that expose different slices of information (run metadata, quality metrics, client identifiers, primer details, control-well status).
During implementation, STAB VIDA delivered a backend page that accepts a \texttt{Plate\_ID} that follows the nomenclature mentioned in (chatGPT please mention the correct chapter) and returns a unified \texttt{.xlsx} with one row per well (up to 96), merging fields from multiple internal sources (run metadata, client/sample registry, primer management, basecalling/quality, trace metrics, control-well status). This \emph{per-plate Excel} became the canonical, read-only input to \textsc{Prometheus}.


\paragraph{Unified Export.}
A backend page accepts a \texttt{Plate\_ID} and returns a downloadable \texttt{.xlsx} containing one row per well (up to 96 rows), with fields merged from multiple backend sources. This \emph{plate-level Excel} became the canonical interface for the project: it preserved well granularity, matched the laboratory’s plate-by-plate workflow, and avoided direct coupling to internal databases or proprietary UIs.

\paragraph{Confidentiality.}
Client names are replaced by pseudonymous \texttt{Client\_ID}s in the export. Each file is saved as \texttt{\{PlateName\}.xlsx} and logged with export timestamp and, when available, the triggering user and backend version.

\paragraph{Rationale.}
(i) The laboratory team already reviews data plate-by-plate; (ii) model training and evaluation are defined \emph{within} plates; and (iii) several required attributes originate from different backend pages. A unified export ensured consistent joins, minimized manual handling, and enabled reproducible experiments.

\begin{table}[H]
\centering
\caption{Backend sources and example fields included in the unified per-plate export.}
\label{tab:backend_sources}
\begin{tabular}{|p{3.6cm}|p{6.7cm}|p{5.1cm}|}
\hline
\textbf{Backend Source (internal)} & \textbf{Example Fields} & \textbf{Notes} \\ \hline
Run metadata / plate view & \texttt{Plate\_ID}, \texttt{Well\_POS}, \texttt{Reaction\_ID}, date & Primary keys, scheduling \\ \hline
Client/sample registry & \texttt{Client\_ID}, \texttt{DNA\_ID}, \texttt{Barcode} & May be missing for some samples \\ \hline
Primer management & \texttt{Primer\_ID}, \texttt{Primer\_Sequence} & Primer can be lab-added \\ \hline
Basecalling/quality & \texttt{DNA\_Sequence}, \texttt{Base\_Length}, \texttt{Quality\_Scores} & Derived from \texttt{.phd.1}/\texttt{.qual} \\ \hline
Trace metrics & \texttt{DyeSignal}, \texttt{Noise}, \texttt{Spacing}, \texttt{TRACE\_SCORE} & From \texttt{.ab1}/\texttt{.qualtrace} \\ \hline
\end{tabular}
\end{table}

\paragraph{Consistency Checks (at ingestion).}
We collaborated with STAB VIDA’s backend engineering team to validate the export. Multiple test exports were cross-checked to confirm field completeness and consistency with expectations.

\paragraph{Scope Note.}
This subsection documents the operational access path realized during implementation. The internal backend itself is out of scope; our artifacts and experiments depend only on the exported per-plate Excel files.


\section{Schema Revision \& Feature Policy}
\label{sec:schema_revision}

The unified export (Section~\ref{sec:impl_backend_access}) enabled us to \emph{revise} the initial draft schema from Chapter~\ref{cha:Proposal} (cf.\ \S\ref{sec:initial_architecture}) into a final, model-ready specification. This revision was driven by three principles learned during co-design with the laboratory:

\begin{enumerate}
  \item \textbf{Determinism over subjectivity.} We favor fields that are machine-deterministic and reproducible across plates. Free-text, user-entered identifiers (e.g., \texttt{DNA\_ID}, \texttt{Primer\_ID}) may be subjective (synonyms, typos, lab conventions) and are therefore \emph{not} used by the classifier.\footnote{Identifiers remain available for explanations and rule checks. See also \S\ref{sec:id_hygiene}.}
  \item \textbf{Plate locality.} Features must reflect intra-plate reasoning (relative to sibling wells), avoiding cross-plate leakage.
  \item \textbf{Safety-first \& leakage control.} We avoid features that encode lab outcomes or policies (e.g., control-well verdicts) to prevent target leakage and to keep the pipeline informative even when routine QC fails.
\end{enumerate}

\subsection{Final Per-Well Input Schema (with Roles)}
\label{sec:final_schema_roles}

Table~\ref{tab:schema_roles} lists the columns available in the \emph{per-plate Excel} and their role in the pipeline. ``Model'' means used by the classifier; ``Rules/Explain'' means used by the post-hoc logic and human-readable exports; ``Reporting Only'' means kept for traceability but not used downstream; ``Excluded'' means intentionally dropped at ingestion.

\begin{table}[H]
\centering
\caption{Per-well columns (exact export) and their role in the final pipeline.}
\label{tab:schema_roles}
\begin{tabular}{|p{4.0cm}|p{4.0cm}|p{3.1cm}|p{6.3cm}|}
\hline
\textbf{Column} & \textbf{Type / Origin} & \textbf{Role} & \textbf{Rationale} \\ \hline

\texttt{Plate\_ID}, \texttt{Well\_Position}, \texttt{Reaction\_ID}, \texttt{Worksheet\_Reaction\_ID}
& Backend / keys
& Rules/Explain
& Traceability, grouping, dedup; not predictive (avoid leakage). \\ \hline

\texttt{DNA\_Sequence}, \texttt{DNA\_Sequence\_Quality}
& Basecalling-derived
& Model
& Drive trimming (Q20$\times$10), 4-mer windows, AE latents and reconstruction error. \\ \hline

\texttt{TRACE\_SCORE}, \texttt{Noise\_Level}, \texttt{Dye\_Signal}, \texttt{QtClass}, \texttt{PEAK\_WIDTH}, \texttt{DETECTOR\_OVERLOAD}, \texttt{BUBBLE}, \texttt{EARLY\_SIGNAL}, \texttt{MID\_SIGNAL}, \texttt{LATE\_SIGNAL}, \texttt{INDEL}, \texttt{EARLY\_MIX}, \texttt{LATEMIX}
& Instrument / trace metrics (\texttt{.ab1}/\texttt{.qualtrace})
& Model
& Stable QC proxies and artefact flags; empirically useful under plate-wise CV. \\ \hline

\texttt{PCR\_Size}, \texttt{Purification\_Status}
& LIMS / registry
& Model
& Included (normalized); \texttt{PCR\_Size} uses \texttt{-1} sentinel when missing. \\ \hline

\texttt{TOTAL\_BASES}, \texttt{GOOD\_BASES}
& Derived counts
& \textit{Excluded}
& Redundant with trimming outcomes; removal improved stability (ablation). \\ \hline

\texttt{Client\_ID} (pseudonymous)
& LIMS / registry
& Rules/Explain
& For mixed-client neighbourhood rules and explanations; \emph{excluded from classifier} to prevent shortcut learning. \\ \hline

\texttt{DNA\_ID}, \texttt{Primer\_ID}
& Free-text identifiers
& Rules/Explain
& Subjective/inconsistent across submissions; \emph{excluded from classifier} to avoid metadata dominance and cross-plate leakage. \\ \hline

\texttt{Barcode}
& LIMS / logistics
& Reporting Only
& Operational/audit metadata; not predictive. \\ \hline

\texttt{Anomaly}
& Manual label (rare)
& Reporting Only
& Evaluation only; never used in training. \\ \hline
\end{tabular}
\end{table}


\paragraph{Engineered features (not raw columns).}
From these inputs we derive: (i) \textbf{AE features} (reconstruction error; 32-d latent per well), (ii) \textbf{similarity features} from plate-local BLAST-like identity ($\geq 66\%$) and nearest-neighbour statistics, and (iii) \textbf{meta flags} (\texttt{Short\_Read}, \texttt{Has\_Non\_ACTG\_Bases}). These engineered variables are model-deterministic and reproducible.

\subsection{Why Some Fields Are Excluded from the Classifier}
\label{sec:exclusions_why}
\begin{itemize}
  \item \textbf{Control-well status.} Encodes a lab decision that can trivially predict ``bad plates'' and mask within-plate patterns. The lab explicitly requested insight \emph{even when} the control fails; we therefore keep it for reporting but exclude it from modeling.
  \item \textbf{Free-text identifiers (\texttt{DNA\_ID}, \texttt{Primer\_ID}).} Naming conventions are subjective (synonyms/typos); when included, the model learned shortcuts and suppressed sequence features (confirmed via permutation importance). They remain available to rules/explanations.
  \item \textbf{Client identifiers.} \texttt{Client\_Name} is removed for privacy; \texttt{Client\_ID} is kept for rules/explanations but excluded from the classifier to avoid cross-plate leakage and metadata dominance.
  \item \textbf{Redundant counts (\texttt{TOTAL\_BASES}, \texttt{GOOD\_BASES}).} Highly correlated with trimming; excluding them improved stability.
  \item \textbf{Direction (forward/reverse).} No reliable field in routine exports; inconsistent ad-hoc tags (``F''/``R''). We therefore do not model direction; reverse-complement checks are \emph{opportunistic} when a trustworthy pairing is present (see \S\ref{sec:direction_justification}).
\end{itemize}

\subsection{Resulting Feature Whitelist (Classifier)}
\label{sec:whitelist}
\begin{itemize}
  \item \textbf{Sequence-derived:} 32-d AE latent; reconstruction error; plate-local nearest-neighbour identity.
  \item \textbf{Trace/instrument:} \texttt{TRACE\_SCORE}, \texttt{Noise\_Level}, \texttt{PEAK\_WIDTH}, artefact flags, region qualities (e.g., EARLY/MID/LATE\_SIGNAL).
  \item \textbf{Meta flags:} \texttt{Short\_Read}, \texttt{Has\_Non\_ACTG\_Bases}.
  \item \textbf{Calibrated threshold:} decision threshold $\tau=0.47$ (see Chapter~\ref{cha:Evaluation}).
\end{itemize}
Identifiers (\texttt{Client\_ID}, \texttt{DNA\_ID}, \texttt{Primer\_ID}) are \emph{excluded from the classifier} but are used in the post-hoc rule layer and in human-readable exports for transparency and actionability.


\section{System Overview and Orchestration}
\label{sec:system_overview}

A watcher process \texttt{deploy\_prometheus.py} runs continuously at the project root. It polls the \texttt{input/} folder every few seconds and processes plates \emph{sequentially} (one at a time) through Steps~1--4. \textbf{After each attempt—success or failure—the input Excel is moved to \texttt{input/processed/}.} To re-run a failed plate, the file must be re-added to \texttt{input/}. After a successful run, a background routine (Step~5) is launched asynchronously for optional historical validation.

\begin{enumerate}
  \item \textbf{Step~1 -- Preprocessing} (\texttt{preprocess\_plates\_wrapper.py}): Q20 trimming, ambiguity flags, position-aware 4-mer tokenization, and plate-local similarity ($\geq$66\%).
  \item \textbf{Step~2 -- Autoencoder (per plate)} (\texttt{auto\_encoder\_wrapper.py}): train seq-to-seq Conv1D AE; export per-well latent vectors and reconstruction errors.
  \item \textbf{Step~3 -- Features \& Classifier} (\texttt{build\_features\_wrapper.py}, \texttt{lgbm\_classifier\_wrapper.py}): merge features; score with LightGBM (plate-wise CV during development, calibrated threshold).
  \item \textbf{Step~4 -- Post-hoc Rules \& Exports} (\texttt{generate\_results\_wrapper.py}): fuse model scores with rules; save interpretable CSVs.
  \item \textbf{Step~5 -- (Async) Historical/Taxonomic Check} (\texttt{verify\_anomalies\_with\_history.py}): launched \emph{after} a successful run to enrich flagged wells with optional BLAST taxonomy and customer-history alignment; runs in the background.
\end{enumerate}

\noindent\textit{Artifact locations.} Steps~1 and~2 write staging artifacts under \texttt{Step\_1/output/} and \texttt{Step\_2/output/}. The orchestrator copies \emph{and opens} the plate layout HTML at \texttt{results/\{plate\}/\{plate\}\_layout.html}. Step~3 writes \texttt{results/\{plate\}/features\_lgbm.csv} and \texttt{results/\{plate\}/predictions\_lgbm.csv}; Step~4 writes \texttt{results/\{plate\}/predictions\_interpretable.csv} and \texttt{results/\{plate\}/predictions\_interpretable\_labview.csv}.

\section{From Proposal to Implementation: Stepwise Evolution}
\label{sec:stepwise_evolution}

This section bridges Chapter~\ref{cha:Proposal} to the implemented pipeline by comparing, per step, what was proposed, what we observed, and the change we made. Quantitative evidence for these pivots is presented in Chapter~\ref{cha:Evaluation}.


\subsection*{Step 1 — Data Processing \& Similarity}
\paragraph{Proposal (Ch.~\ref{cha:Proposal}).}
Global clustering with DBSCAN on PCA-reduced $k$-mer frequencies; basic end-trim.

\paragraph{Observed issues.}
(i) Bag-of-$k$-mers lost order (single-base mismatches slipped through). 
(ii) Global cluster IDs encouraged cross-plate leakage; clusters are inherently plate-local.
(iii) Tail noise (\texttt{N}/\texttt{Y}) polluted features; short reads distorted representations.

\paragraph{Implemented change.}
(i) Plate-local BLAST-like pairwise identity ($\geq 66\%$) to form in-plate neighbourhoods (no cross-plate reuse). 
(ii) Order-sensitive 4-mer windows (stride $=1$ for encoding; exported as 150-token windows with stride $=50$). 
(iii) Central Q20$\times$10 trimming; ambiguous bases \emph{flagged} (not encoded); reads $<150$ bases bypass AE.

\paragraph{Takeaway.} Treat plates as isolated universes; keep order; do not encode ambiguity.

\subsection*{Step 2 — Representation Learning (Autoencoder)}
\paragraph{Proposal (Ch.~\ref{cha:Proposal}).}
No sequence model; PCA on $k$-mers; Random Forest downstream.

\paragraph{Observed issues.}
Missing order sensitivity; global models underfit plate-specific distributions; padding short reads injected noise; mapping \texttt{N}/\texttt{Y} to neutral tokens corrupted latents.

\paragraph{Implemented change.}
Per-plate Conv1D autoencoder over 4-mer tokens; skip AE when $<$150 bases or ambiguity remains (\texttt{Short\_Read}/\texttt{Has\_Non\_ACTG\_Bases}); export 32-d latent + reconstruction error per well.

\paragraph{Takeaway.} Small per-plate encoders capture local regularities that global models miss.

\subsection*{Step 3 — Classifier \& Leakage Control}
\paragraph{Proposal (Ch.~\ref{cha:Proposal}).}
Random Forest on cluster-derived features; per-well splits.

\paragraph{Observed issues.}
Per-well splits leak plate context; RF/MLP unstable under class imbalance; metadata shortcuts (\texttt{Client\_ID}/\texttt{Primer\_ID}) suppress sequence features.

\paragraph{Implemented change.}
LightGBM with GroupKFold by plate and calibrated threshold; remove \texttt{Client\_ID}/\texttt{Primer\_ID} from the model (kept for explanations/rules); positive class weighting; permutation-importance checks. Quantitative comparisons across RF/XGB/LGBM are in Chapter~\ref{cha:Evaluation}.

\paragraph{Takeaway.} Grouped splits, calibrated boosting, and careful feature hygiene prevent illusory gains.

\subsection*{Step 4 — Post-hoc Rules \& Reporting}
\paragraph{Proposal (Ch.~\ref{cha:Proposal}).}
Purely model-driven decisions.

\paragraph{Observed issues.}
Heterogeneous anomaly types (contamination vs.\ forward/reverse mismatch vs.\ short/ambiguous reads) benefit from explicit logic; the lab needs traceable reasons and a compact export.

\paragraph{Implemented change.}
Weighted rules (cross-client homology, cross-primer consistency, ambiguity/short-read handling, forward/reverse reverse-complement check when available), fused with model probability; two exports: an interpretable CSV and a LabVIEW-ready compact CSV. Precision–recall changes due to fusion are presented in Chapter~\ref{cha:Evaluation}.

\section{Data and Final Per-Well Schema}
\label{sec:data_schema}
Each plate arrives as a single Excel file with one row per well (sequence, quality/trace metrics, metadata). The schema used in implementation is:

\begin{table}[H]
  \centering
  \caption{Final schema used for per-well data (Excel input).}
  \label{tab:final_table_schema_impl}
  \begin{tabular}{|l|p{11cm}|}
    \hline
    \textbf{Column} & \textbf{Description} \\ \hline
    Plate\_ID, Well\_Position & Plate and well identifiers. \\ \hline
    Client\_ID, Barcode, DNA\_ID, Primer\_ID & Submission metadata (may be missing/duplicated). \\ \hline
    Purification\_Status, PCR\_Size & Purification flag and PCR size (missing $\rightarrow -1$ sentinel). \\ \hline
    DNA\_Sequence, DNA\_Sequence\_Quality & Base string and per-base Phred string. \\ \hline
    TRACE\_SCORE, Noise\_Level, QtClass, PEAK\_WIDTH, artefact flags & Instrument/trace quality metrics and booleans. \\ \hline
    TOTAL\_BASES, GOOD\_BASES, INDEL, EARLY/MID/LATE\_SIGNAL, EARLY\_MIX, LATEMIX & Derived quality/structure features. \\ \hline
    Anomaly & Manual label (if available) for evaluation only. \\ \hline
  \end{tabular}
\end{table}

\noindent\textit{Feature usage note.} Although \texttt{TOTAL\_BASES} and \texttt{GOOD\_BASES} may be present in the raw Excel, they are \emph{not} used by the classifier because they correlate with trimming outcomes and introduced redundancy and noise in early trials.

\section{Preprocessing}
\label{sec:preproc}

\subsection{Quality Trimming and Ambiguity Handling}
Sequences are trimmed from both ends until \textbf{10 consecutive bases} have Phred $\geq 20$ (Q20 $\approx$99\% accuracy). Ambiguous IUPAC bases (\texttt{N}, \texttt{Y}, \ldots) are \emph{not} fed to the sequence model; wells that still contain ambiguity after trimming are flagged (\texttt{Has\_Non\_ACTG\_Bases}=1). Trimming is anchored on the highest-quality central segment and expands outwards until the Q20$\times$10 criterion is satisfied, reducing tail noise.

\subsection{Minimum Length and Short-Read Path}
We build 4-mer windows only for reads with $\geq 150$ trimmed bases. Wells shorter than this threshold skip the AE path (latents/reconstruction become \texttt{NaN}); they are handled by rules and by the tabular classifier using metadata/trace features plus \texttt{Short\_Read}/\texttt{NoLatent} flags.

\subsection{Sequence Representation and Single-Base Sensitivity}
We use overlapping, position-aware 4-mer tokenization into fixed-length \textbf{150-token} windows (4\textsuperscript{mer} vocabulary size $=256$). A single-base difference perturbs local 4-mer composition, which makes mismatches separable in both the AE latent space and the alignment-derived features.

\subsection{Plate-Local Similarity and Clustering Signals}
For each plate we compute pairwise sequence identity using a local BLAST-like alignment; wells with identity $\geq 66\%$ form neighbourhoods. These neighbourhoods are \emph{plate-scoped} (IDs not reused across plates) and serve to engineer:
\begin{itemize}
  \item \texttt{Mixed\_Client} / \texttt{Mixed\_Primer} flags within a neighbourhood,
  \item nearest-neighbour identity features,
  \item ``same DNA\_ID, different primer'' consistency checks (and reverse-complement checks when direction is available).
\end{itemize}

\subsection{Curation Notes}
A falsely labelled well (\texttt{F3}) was removed after manual verification. \texttt{PCR\_Size} is normalised and uses \texttt{-1} when absent.

\subsection{Per-Step Inputs and Outputs (I/O Contracts)}
\label{sec:io_contracts}

\begin{table}[H]\centering
\caption{Step~1 -- Preprocessing (\texttt{preprocess\_plates\_wrapper.py})}
\begin{tabular}{|p{3.8cm}|p{9.8cm}|}\hline
\textbf{Input} & Excel plate (\texttt{input/\{plate\}.xlsx}) \\ \hline
\textbf{Ops} & Q20 trimming (10 consecutive bases), ambiguity flags (N/Y), 4-mer tokenization into fixed-length 150-token windows for reads $\geq 150$, plate-local identity ($\geq 66\%$). \\ \hline
\textbf{Output} & \texttt{Step\_1/output/\{plate\}\_kmer\_windows.npy}; \texttt{Step\_1/output/\{plate\}\_window\_map.npy}; \texttt{Step\_1/output/\{plate\}\_metadata.xlsx}; and a BLAST neighbourhood layout HTML under \texttt{Step\_1/output/visualizations/}. The orchestrator copies and opens the HTML at \texttt{results/\{plate\}/\{plate\}\_layout.html}. \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]\centering
\caption{Step~2 -- Autoencoder (\texttt{auto\_encoder\_wrapper.py})}
\begin{tabular}{|p{3.8cm}|p{9.8cm}|}\hline
\textbf{Input} & \texttt{\{plate\}\_kmer\_windows.npy}, \texttt{\{plate\}\_window\_map.npy}, metadata (from Step~1 outputs). \\ \hline
\textbf{Ops} & Train per-plate Embedding+Conv1D seq-to-seq AE over 150-token inputs; export latent (mean-pooled) and reconstruction error per well. \\ \hline
\textbf{Output} & \texttt{Step\_2/output/\{plate\}\_autoencoder.h5}, \texttt{Step\_2/output/\{plate\}\_latent\_vectors.npy}, \texttt{Step\_2/output/\{plate\}\_with\_errors.xlsx}, \texttt{Step\_2/output/\{plate\}\_loss\_curve.png}. \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]\centering
\caption{Step~3 -- Features \& Classifier}
\begin{tabular}{|p{3.8cm}|p{9.8cm}|}\hline
\textbf{Input} & AE exports + Step~1 metadata + similarity features. \\ \hline
\textbf{Ops} & Build tabular features (drops \texttt{Client\_ID}/\texttt{Primer\_ID} for modeling). LightGBM scoring with calibrated threshold. \\ \hline
\textbf{Output} & \texttt{results/\{plate\}/features\_lgbm.csv}, \texttt{results/\{plate\}/predictions\_lgbm.csv}. \\ \hline
\end{tabular}
\end{table}

\begin{table}[H]\centering
\caption{Step~4 — Post-hoc Rules \& Exports (\texttt{generate\_results\_wrapper.py}).}
\begin{tabular}{|p{3.8cm}|p{9.8cm}|}\hline
\textbf{Input} & \texttt{predictions\_lgbm.csv} + rule features. \\ \hline
\textbf{Ops} & Weighted rule scoring and fusion with $\hat p$. Threshold values were selected empirically during validation (Chapter~\ref{cha:Evaluation}). \\ \hline
\textbf{Output} & \texttt{predictions\_interpretable.csv}, \texttt{predictions\_interpretable\_labview.csv}. \\ \hline
\end{tabular}
\end{table}

\section{Per-Plate Conv1D Autoencoder}
\label{sec:ae}

\paragraph{Rationale.} Plates are independent operational units; training one AE per plate lets the model learn only that plate’s distribution (``small agents''). A global AE was tested and underperformed; the plate AE was kept (a configuration flag allows switching).

\paragraph{Model.} A sequence-to-sequence Conv1D autoencoder over 4-mer tokens:
\begin{itemize}
  \item \textbf{Tokenization:} 4-mer vocabulary ($|\mathcal{V}|=256$), inputs are \textbf{150-token} windows derived from trimmed reads.
  \item \textbf{Encoder/Decoder:} \texttt{Embedding}$(256,32)$ with Conv1D blocks to a \emph{bottleneck} of 32; symmetric decoding with a \texttt{TimeDistributed(Dense(256, softmax))}.
  \item \textbf{Loss \& training:} sparse categorical cross-entropy; \texttt{BATCH\_SIZE=64}, \texttt{EPOCHS=40}, early stopping (\texttt{patience=5}).
\end{itemize}

Outputs per well: (i) mean reconstruction error across windows, (ii) a 32-dim latent (mean-pooled). Reads $<150$ bases or with post-trim ambiguity produce \texttt{Short\_Read}/\texttt{Has\_Non\_ACTG\_Bases} flags and skip AE.

\section{Classifier and Evaluation Protocol}
\label{sec:clf}

\subsection{Retired Configurations}
\label{sec:retired_configs}
We trialled (i) a global AE trained across plates, (ii) an MLP classifier with binary cross-entropy and class weights, and (iii) XGBoost. The global AE underperformed due to loss of plate context; the MLP was more sensitive to class imbalance and data scarcity; XGBoost was comparable to LightGBM but less stable under plate-wise cross-validation. LightGBM with calibrated thresholding was therefore adopted.

\subsection{Tabular Classifier}
We compared MLP, XGBoost, and LightGBM; LightGBM was selected for stability under plate-wise cross-validation and strong performance with mixed dense/flag features. Class imbalance is addressed via positive class weighting and decision-threshold tuning (recall-priority). The deployment decision threshold is $\tau=0.47$, calibrated on validation folds (see Chapter~\ref{cha:Evaluation}); Step~4 later fuses $\hat p$ with rules for deployment decisions.

\subsection{Train/Test Split and Leakage Control}
All splits are \textbf{by plate} (plate-wise GroupKFold): entire plates are held out. This prevents leakage that would occur if wells from the same plate appeared in both train and test.\footnote{Earlier 70/30 per-plate splits were discarded due to implicit leakage.}
During training, each fold produces a model; deployment trains a single final model on all training plates after CV hyperparameter selection, avoiding fold-specific $\hat{y}$ discrepancies.

\subsection{Feature Engineering and Leakage Mitigation}
Features are grouped as:
\begin{itemize}
  \item \textbf{AE features:} reconstruction error; 32-dim latent.
  \item \textbf{Similarity/rule features:} nearest-neighbour identity; \texttt{Mixed\_Client}/\texttt{Mixed\_Primer}; ``same DNA\_ID, different primer'' checks; forward/reverse reverse-complement similarity.
  \item \textbf{Trace/instrument:} TRACE\_SCORE, Noise\_Level, PEAK\_WIDTH, artefact flags, region qualities.
  \item \textbf{Meta flags:} \texttt{Short\_Read}, \texttt{Has\_Non\_ACTG\_Bases}.
\end{itemize}
We explicitly \emph{remove} \texttt{Client\_ID} and \texttt{Primer\_ID} from classifier inputs to avoid shortcut learning and cross-plate leakage; both remain available to the rule layer and for explanations. Permutation importance checks verified that sequence-derived features retained predictive weight after these removals (see Chapter~\ref{cha:Evaluation}).

\section{Post-hoc Rule Layer}
\label{sec:rules}
Rules are applied after model scoring; they can \emph{escalate} or \emph{override} based on lab policy. We compute a weighted rule score $S$ (sum of rule weights) and then fuse it with the model probability $\hat p$. Threshold values were selected empirically during validation (Chapter~\ref{cha:Evaluation}).

\subsection{Rule inventory (excerpt)}
\begin{itemize}
  \item Reverse-complement mismatch between likely forward/reverse pair (when available).
  \item Same \texttt{DNA\_ID} with different primers but high mismatch.
  \item Nearest neighbour is a different client with identity $\geq 66\%$; or a neighbourhood mixing multiple clients.
  \item High AE reconstruction error (per-well).
  \item Singleton well highly similar to a different client.
  \item High model confidence only (e.g., $\hat p > 0.90$).
\end{itemize}

\subsection{Fusion With Model Probability}
A well is flagged when any of the following holds:
\[
\boxed{\;
S \ge 1.0
\;\;\lor\;\;
(\text{Recon\_Error} > 7.5\times 10^{-3} \land \hat p > 0.50)
\;\;\lor\;\;
(S \ge 0.5 \land \hat p > 0.75)
\;\;\lor\;\;
\hat p > 0.95 \;
}
\]

\paragraph{Outputs.} For plate \texttt{\textit{P}}, Step~4 writes:
\begin{itemize}
  \item \texttt{results/\textit{P}/predictions\_interpretable.csv} (full reasons and intermediate fields),
  \item \texttt{results/\textit{P}/predictions\_interpretable\_labview.csv} (compact export with \texttt{Plate\_Name, Well\_Position, Client\_ID, DNA\_ID, Primer\_ID, DNA\_Sequence, Anomaly\_Probability, Weighted\_Rule\_Score, Num\_Reasons, Anomaly\_Reason, Explanation, Anomaly\_Flagged}).
\end{itemize}
We also assign an \texttt{Anomaly\_Confidence} label (\emph{High} if $S\ge 1.5$, \emph{Medium} if $S\ge 1.0$, \emph{Low} if $S>0$, else \emph{None}).

\section{Limitations and Failure Modes}
\label{sec:limits}
\textbf{Labels.} Only four labelled plates; some anomaly types are rare.  
\textbf{Short/ambiguous reads.} Wells $<150$ bases or with \texttt{N}/\texttt{Y} skip AE; detection then hinges on rules and trace features.  
\textbf{Direction metadata.} Forward/reverse indicators are not always available; when present, reverse-complement checks are applied; otherwise omitted.  
\textbf{Stochasticity.} Seeds are not fixed; minor run-to-run variation is expected (variance ranges in Chapter~\ref{cha:Evaluation} and Appendix).

\section{Reproducibility}
\label{sec:repro}
Processing is modular and scripted; the watcher processes plates serially and never blocks on failures:
\begin{itemize}
  \item \textbf{Preprocessing} (trimming, ambiguity, BLAST-like neighbourhoods; 150-token windows, stride 50).
  \item \textbf{Autoencoder} (per-plate training; latent \& reconstruction export).
  \item \textbf{Feature build} (merge AE, similarity, trace, and flags).
  \item \textbf{Classifier} (GroupKFold by \texttt{Plate\_ID} during development, $\tau=0.47$; final model retrained on all training plates).
  \item \textbf{Results \& rules} (interpretable CSVs, LabVIEW export).
\end{itemize}
\paragraph{Artifacts.} Each run writes to \texttt{results/\{plate\}/}:\\
\texttt{\{plate\}\_kmer\_windows.npy}, \texttt{\{plate\}\_window\_map.npy}, \texttt{\{plate\}\_metadata.xlsx}, \texttt{\{plate\}\_autoencoder.h5}, \texttt{\{plate\}\_latent\_vectors.npy}, \texttt{\{plate\}\_with\_errors.xlsx}, \texttt{\{plate\}\_loss\_curve.png}, \texttt{features\_lgbm.csv}, \texttt{predictions\_lgbm.csv}, \texttt{predictions\_interpretable.csv}, \texttt{predictions\_interpretable\_labview.csv}, and \texttt{\{plate\}\_layout.html}.
