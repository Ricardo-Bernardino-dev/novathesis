%!TEX root = ../template.tex
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% chapter3.tex
%% NOVA thesis document file
%%
%% Chapter with a short latex tutorial and examples
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\typeout{NT FILE chapter3.tex}%

\makeatletter
\newcommand{\ntifpkgloaded}{%
  \@ifpackageloaded%
}
\makeatother


\chapter{Proposal}
\label{cha:Proposal}


This chapter details the choice and implementation of the proposed AI-driven tool, outlining all the important steps for it's development. From the laboratory processes, the data collection, to the AI model proposal itself that will be used to automate well-quarantining, the ultimate goal of this proposal is to develop a system that enhances the efficiency and accuracy of delivered sequencing results while reducing manual effort. By leveraging machine learning techniques, the proposed tool will provide an automated approach to categorizing DNA samples based on their similarity according to multiple fields. This will address the current limitations of manual analysis, improving both speed and reliability in laboratory workflows.

The chapter begins with an overview of the laboratory processes involved in sequencing, including the preparation of samples in a 96-well PCR plate, and it's sequencing using the ABI3730xl DNA sequencer. Next, it discusses the data collection and storage procedures, emphasizing the structured format of sequencing outputs and metadata handling. Finally, it introduces the proposed AI model for use, detailing the methodology for clustering the DNA sequences and automating quality assessment.

\section{Laboratory Processes}
\label{sec:laboratory}

The laboratory processes described here are central to the generation of the data used in this work. These processes involve the handling of DNA samples, their preparation for sequencing, and the subsequent analysis of the results.

\subsection{Sample Preparation and Processing}
The laboratory workflow begins with the reception of DNA samples from various clients. These samples are organized into 96-well PCR plates, where each well is identified by a unique coordinate system: letters A to H for the rows and numbers 1 to 12 for the columns (Figure \ref{fig:96_well_plate}). This organization ensures traceability and efficient handling of multiple samples simultaneously. Samples from the same client are grouped together in neighboring wells, although not all wells need to be occupied for sequencing to proceed. Each plate must contain at least one control well.
\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{96plate.png}
  \caption{A 96-well PCR plate.}
  \label{fig:96_well_plate}
\end{figure}


\begin{figure}[H]
  \centering
  \includegraphics[width=0.8\textwidth]{platecoords.png}
  \caption{Structure and Organization of each PCR plate.}
  \label{fig:platecoords}
\end{figure}

Upon receipt, some samples require human intervention to prepare them for sequencing. For instance, samples with uneven DNA concentrations must be normalized to ensure consistent sequencing quality. Additionally, samples that do not include a primer must have the appropriate primer added by laboratory staff. These steps are critical to ensure the accuracy and reliability of the sequencing results. Each plate also contains 1 well reserved for solely for quality control, named \textit{Control}

Once prepared, these plates are then loaded into the ABI3730xl DNA sequencer, which includes DNA denaturation, primer annealing, extension with fluorescently labeled dideoxynucleotides, and capillary electrophoresis. The ABI3730xl sequencer then generates raw data files containing fluorescence intensity readings, which are subsequently processed to produce DNA sequence alignments.


\subsection{The ABI3730xl DNA Sequencer}
The ABI3730xl DNA sequencer is a high-throughput instrument widely used in genomics for Sanger sequencing. It automates the electrophoresis and fluorescence detection steps, corresponding to steps 3 and 4 of the Sanger sequencing process (Figure \ref{fig:sanger_steps}), allowing for the simultaneous processing of 96-well plates in a single run \cite{smith_capillary_sequencing,abi3730xl_overview}. By leveraging this technology, laboratories can achieve precise and efficient DNA sequencing. 
\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{abi_3730xl_closed.png}
\caption{A closed ABI3730xl capillary electrophoresis DNA analyzer.}
\label{fig:abi_3730xl_closed}
\end{figure}

\begin{figure}[h]
\centering
\includegraphics[width=0.7\textwidth]{abi_3730xl_opened.png}
\caption{An opened ABI3730xl capillary electrophoresis DNA analyzer.}
\label{fig:abi_3730xl_opened}
\end{figure}

\subsection{Data Generation \& Collection}

The effectiveness of any artificial intelligence model relies heavily on the quality and structure of the available data. In this work, the data originates from customer samples sequenced using the ABI3730xl DNA sequencer. Each well in a 96-well PCR plate generates multiple files, including raw fluorescence data, processed DNA sequences, and quality metrics. With each plate containing 96 wells and each well producing 6 distinct files, a single plate yields 576 files. Over time, as multiple plates are processed daily, this results in millions of files, forming a robust dataset for analysis.
The primary file types considered in this work include:

\begin{itemize}
  \item \textbf{Ab1 File}: Contains intensity readings for each of the four fluorescent dyes (A, T, C, G) used in Sanger sequencing, resulting in fluorescent traces. This file is optimized for long sequences (more than 500 bases).
  \item \textbf{Phd1 File}: Contains the DNA sequence derived from the fluorescence traces, along with quality scores and scan numbers.
  \item \textbf{Scf File}: Similar to .ab1 files, .scf files include quality information about the base calls, the chromatogram (also called the electropherogram), and the DNA sequence.
  \item \textbf{Seq File}: A plain text file containing the DNA sequence.
  \item \textbf{Qual File}: Includes the quality scores of each base in the DNA sequence.
  \item \textbf{Qualtrace File}: Contains additional information about the sequencing process, such as PeakStart, DyeSignal, Noise, and Spacing.
\end{itemize}

These files adhere to a strict naming convention: \textbf{ReactionID\_Pos\_DNAID+PrimerID}. 
For example, the file name \texttt{2338715\_A1\_AA8117+Clon\_2+ORB501} can be broken down as follows:
\begin{itemize}
  \item \texttt{2338715}: The unique reaction ID.
  \item \texttt{A1}: The position of the well in the plate (row A, column 1).
  \item \texttt{AA8117+Clon\_2}: The DNA ID, identifying the specific DNA sample.
  \item \texttt{ORB501}: The primer ID, which is optional as some customers provide samples with primers already included.
\end{itemize}
Thus, 6 files are generated for this specific well: 
\begin{itemize}
  \item \texttt{2338715\_A1\_AA8117+Clon\_2+ORB501.ab1}
  \item \texttt{2338715\_A1\_AA8117+Clon\_2+ORB501.phd.1}
  \item \texttt{2338715\_A1\_AA8117+Clon\_2+ORB501.scf}
  \item \texttt{2338715\_A1\_AA8117+Clon\_2+ORB501.seq}
  \item \texttt{2338715\_A1\_AA8117+Clon\_2+ORB501.qual}
  \item \texttt{2338715\_A1\_AA8117+Clon\_2+ORB501.qualtrace}
\end{itemize}

Other relevant and important information about each plate well, such as the associated \textbf{Client's Name}, \textbf{Sequence Length}, \textbf{Primer DNA Sequence} (If applied by the laboratory staff), and the \textbf{Control Well Status} is also available.  
\newline
It's \textbf{important to notice} that even though anomaly cases aren't registered directly in the database as a field or flag, because they are manually verified and immediatly trated after detection, the laboratory team has made the effort to gather information on recent known anomalies that have occured, and this data can be seamlessly integrated as labeled data for this work.
\subsection{Manual Analysis}

After the data is generated, the laboratory staff manually handles quality checks on each plate individually, particularly for identifying possible fluorescence contamination and mismatches in sequencing results. This is a lenghty and thorough process that currently induces a bottleneck in the laboratory workflow. The main steps for quarantining wells are as follows:

\begin{itemize}
  \item \textbf{1. Control Well Check}: The laboratory staff begins by checking the \texttt{control\_well} for each plate. If the control well's \texttt{ok\_flag} is \texttt{NOT OK}, the entire plate is quarantined, as this indicates a problem with the sequencing process. If the control well passes the check, the process moves to the next step.
  \item \textbf{2. Sequence Clustering}: The sequencing software extracts the \texttt{ab1} files from each well (96 wells per plate) and clusters the sequences based on a minimum similarity of 66\%. This clustering is performed to group together DNA samples that are likely to belong to the same biological entity. Each cluster represents a set of related DNA sequences.
  \item \textbf{3. Cluster Verification}: The next step involves verifying these clusters for potential contamination or sequencing errors. Laboratory staff checks for two main conditions:
    \begin{itemize}
      \item \textit{Similar Sequences from Different Clients}: If samples from different clients have very similar DNA sequences, it may suggest fluorescence contamination, triggering a quarantine for further investigation.
      \item \textit{Same Primers with Different Sequences}: If different primers are associated with very similar DNA sequences, this could indicate contamination and thus requires quarantining.
    \end{itemize}
  \item \textbf{4. Forward and Reverse Sequence Matching}: DNA samples are analyzed based on forward and reverse sequencing. If a single base mismatch is detected in the same DNA sample (with matching \texttt{DNAID} and \texttt{primer\_id}), it is flagged for quarantine. In the case where a sample is processed with different primers, a variation in sequence is expected.
\end{itemize}
Sometimes certain samples do not appear to be contaminated, but the overall suspicion of such, or the poor quality presented, is enough to justify a quarantine, due to the importance of delivering accurate results.
After the anomalies are quarantined, these possibly contaminated samples are re-sequenced for an attempt at acquiring higher quality and accuracy, while the remaining samples are delivered to the client.

\section{Proposed Solution}
\label{sec:model}

The importance of automating this manual process leverging AI-based technology now comes into place. Removing the need for manual individual analysis of all samples per plate is as important as delivring accurate results that would reflect a seamlessly human intervention.
The proposed work handles the early processes of processing the available data for model training, the model selection itself, and the validation and future deployability of the tool.

\subsection{Database Structure}
For model purposes, the database is structured with only relevant information, combining data derived from the majority of the introduced files with additional metadata. To simplify data management and improve query efficiency, a single table is proposed to store all relevant sequencing data and metadata. Below is the schema for this unified table:

\begin{table}[H]
  \centering
  \begin{tabular}{|l|l|p{8cm}|}
    \hline
    \textbf{Column Name} & \textbf{Data Type} & \textbf{Description} \\ \hline
    \texttt{Plate\_ID} & String & Unique identifier for each 96-well PCR plate. \\ \hline
    \texttt{Well\_POS} & String & Unique identifier for each well position (e.g., A1, B2). \\ \hline
    \texttt{Reaction\_ID} & String & Unique identifier for the reaction associated with the well. \\ \hline
    \texttt{DNA\_ID} & String & Identifier for the DNA sample. \\ \hline
    \texttt{Primer\_ID} & String & Identifier for the primer used (if applicable). \\ \hline
    \texttt{Client\_Name} & String & Name of the client associated with the sample. \\ \hline
    \texttt{Control\_Well\_Status} & String & Status of the control well (e.g., "OK" or "Quarantine"). \\ \hline
    \texttt{DNA\_Sequence} & Text & The DNA sequence derived from the `.seq` or `.phd.1` file. \\ \hline
    \texttt{Base\_Length} & Integer & The total number of bases of the DNA sequence. \\ \hline
    \texttt{Quality\_Scores} & Text & Quality scores for each base in the sequence (from `.qual` or `.phd.1` files). \\ \hline
    \texttt{Fluorescence\_Traces} & Text & Fluorescence intensity readings (from `.ab1` or `.scf` files). \\ \hline
    \texttt{PCR\_Size} & Integer & Size of the PCR product. \\ \hline
    \texttt{Purification\_Details} & Text & Information about the purification process. \\ \hline
    \texttt{Primer\_Sequence} & Text & Sequence of the primer used (if manually added by staff). \\ \hline
    \texttt{Date\_Processed} & Date & Date the plate was processed. \\ \hline
  \end{tabular}
  \caption{Unified Table Structure for Sequencing Data and Metadata.}
  \label{tab:unified_table}
\end{table}

This unified table structure ensures that all relevant information is stored in a single location, simplifying data retrieval and analysis. It includes fields for plate and well identification, sequencing data, quality metrics, and metadata, making it suitable for both clustering and contamination detection tasks.

For training, the data is consolidated into a unified table for efficient preprocessing and model development. For deployment, the AI-based tool is integrated directly with the company's servers to fetch and process data in real time.

\subsection{Data Preprocessing}

To ensure optimal input quality for the AI-based model, multiple preprocessing steps are performed on the raw sequencing data. This includes sequence trimming, feature extraction, normalization of numerical features, and handling categorical/text-based attributes appropriately.

\subsubsection{Sequence Trimming}
Raw sequencing data contains noise, in the form of poor base quality, particularly at the start and end of sequences. At the beginning, this is primarily due to inefficient primer binding and weaker signal intensities as the primer binds and starts the reaction. At the end, the reduced availability of chain-terminating nucleotides (ddNTPs), declining polymerase efficiency, and signal saturation contribute to weaker and less accurate readings. \cite{sanger_method_original}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{noise1.png}
  \caption{Visualization of noise in the beggining of the DNA sequence, using 4peaks.}
  \label{fig:noise1}
\end{figure}

\begin{figure}[h]
  \centering
  \includegraphics[width=0.7\textwidth]{noise2.png}
  \caption{Visualization of noise in the end of the DNA sequence, using 4peaks.}
  \label{fig:noise2}
\end{figure}

To improve downstream analysis, sequences are trimmed using the following criterion:

\begin{itemize}
    \item Bases are removed from the start and end of the sequence until \textbf{10 consecutive bases} have a \textbf{quality score} greater than 20.
    \item This ensures that only high-quality sequence regions are used for further processing.
\end{itemize}

The trimmed sequences are then stored for subsequent steps.

\subsubsection{Sequence Encoding}
To represent DNA sequences in a numerical format suitable for clustering:
\begin{itemize}
    \item \textbf{k-mer Frequency Encoding}:
    \begin{itemize}
        \item Each DNA sequence is converted into a vector of k-mer frequencies.
        \item A k-mer size of 4 is chosen to balance specificity and computational efficiency.
        \item For example, a 4-mer approach splits the sequence into overlapping subsequences of length 4 (tetramers) and counts their occurrences.
        \item This method captures local sequence patterns and is particularly useful for clustering algorithms like DBSCAN.
    \end{itemize}
\end{itemize}

\subsubsection{Normalization}
To ensure consistent scaling of features, while also ensuring numerical features contribute equally to the model:
\begin{itemize}
    \item \textbf{Sequence Feature Normalization}:
    \begin{itemize}
        \item The k-mer frequency vectors and the numerical features such as uality scores, sequence lengths, and other quantitative features, are normalized using \textbf{min-max scaling} or \textbf{z-score normalization}.
        \item This ensures all features are on a similar scale, preventing any single feature from dominating the clustering process.
    
    \end{itemize}
\end{itemize}

\subsubsection{Dimensionality Reduction}
To handle the high dimensionality of k-mer frequency vectors:
\begin{itemize}
    \item \textbf{Principal Component Analysis (PCA)}:
    \begin{itemize}
        \item PCA is applied to reduce the dimensionality of the feature space while retaining the most significant variance.
        \item This step reduces computational complexity and mitigates the risk of overfitting.
        \item The number of principal components is selected based on the cumulative explained variance (e.g., retaining 95\% of the variance).
    \end{itemize}
\end{itemize}


\subsection{Model Selection \& Development}

The goal of the proposed AI-based tool is to fully automate the process currently performed manually by the laboratory staff. This involves categorizing DNA samples into wells based on their similarity and identifying anomalies that could indicate contamination, sequencing errors, or other irregularities. Since the proposed work is based on AI there is a clear need to choose appropriate models for specific tasks. 
In this work's case, the nature of the problem combined with the manual tasks done by laboratory personel, imply that more than one model should be used to process data for different purposes. Hence a structured pipeline is the best choice for streamlining the data from one model to another.
Thus, a hybrid approach is purposed with 2 Machine Learning Models.


\subsubsection{Unsupervised Learning for Clustering}
Given the lack of labeled data in the initial stages, unsupervised learning is particularly suitable for this task, as we first need to group samples that appear to be similar to each other together, indicating they are possibly from the same client. The following model appears to be the best choice:

\begin{itemize}
    \item \textbf{Clustering with DBSCAN}:
    \begin{itemize}
        \item DBSCAN is chosen for its ability to identify clusters of varying shapes and sizes while automatically detecting outliers (anomalies).
        \item Unlike centroid-based methods like K-means, DBSCAN does not require predefined cluster numbers, making it adaptable to diverse datasets.
        \item It is robust to noise, which is critical for identifying mislabeled or contaminated wells.
    \end{itemize}
\end{itemize}

The DBSCAN algorithm is implemented as follows:

\begin{itemize}
    \item \textbf{Parameter Tuning}:
    \begin{itemize}
        \item The key parameters—\textit{eps} (maximum distance between samples in the same cluster) and \textit{min\_samples} (minimum number of samples in a cluster)—are optimized using grid search and silhouette score evaluation.
    \end{itemize}

    \item \textbf{Anomaly Detection}:
    \begin{itemize}
        \item Samples not assigned to any cluster by DBSCAN are flagged as potential anomalies for further investigation.
    \end{itemize}
\end{itemize}

\subsubsection{Semi-Supervised Learning for Anomaly Detection}
To leverage the few anomaly cases registered by the laboratory team, which can be treated as labeled data labeled, a semi-supervised learning approach is proposed. The following method is selected:

\begin{itemize}
    \item \textbf{Self-Training with DBSCAN using Random Forest}:
    \begin{itemize}
        \item DBSCAN is used to generate initial cluster labels, which are then refined using a small set of labeled anomalies.
        \item A classifier (e.g., Random Forest or Support Vector Machine) is trained on the labeled anomalies to improve detection accuracy.
        \item This approach reduces the reliance on large labeled datasets while improving the model's ability to detect rare anomalies.
    \end{itemize}
\end{itemize}

The semi-supervised learning pipeline is developed as follows:

\begin{itemize}
    \item \textbf{Label Generation}:
    \begin{itemize}
        \item Anomalies detected by DBSCAN are used as initial labels for training the classifier.
    \end{itemize}

    \item \textbf{Classifier Training}:
    \begin{itemize}
        \item A Random Forest classifier is trained on the labeled anomalies due to its robustness and interpretability.
        \item Feature importance analysis is performed to identify which k-mers contribute most to anomaly detection.
    \end{itemize}

    \item \textbf{Prediction}:
    \begin{itemize}
        \item The trained classifier predicts anomalies in new sequencing data, providing automated quarantine recommendations.
    \end{itemize}
\end{itemize}

\subsection{Evaluation Metrics \& Model Refinement}
To ensure the model's effectiveness and improve its performance, the following evaluation and refinement steps are employed. For clustering performance, the silhouette score measures cluster separation and cohesion, while the Davies-Bouldin index assesses cluster compactness and separation. For anomaly detection, precision, recall, F1-score, and the confusion matrix are used to evaluate anomaly identification accuracy and analyze false positives and false negatives.
The model development process includes iterative refinement. DBSCAN parameters (e.g. , \texttt{eps} , \texttt{min\_samples} ) and classifier hyperparameters (e.g. , Random Forest) are fine-tuned using grid search or random search. Additionally, rule-based post-processing (e.g. , sequence length thresholds, mismatch tolerances) is applied to reduce false positives and improve accuracy.

\subsection{Frameworks, Languages \& Tools}
The development and implementation of the proposed AI-driven tool rely on the following technologies, selected for their suitability in data processing, machine learning, and deployment:

\begin{table}[h]
\centering
\caption{Frameworks, Languages \& Tools}
\label{tab:frameworks}
\begin{tabular}{|p{3.5cm}|p{3.5cm}|p{6cm}|}
\hline
\textbf{Category} & \textbf{Tools/Frameworks} & \textbf{Choice Justification} \\ \hline
Programming Language & Python & Widely used for scientific computing and machine learning, with extensive libraries. \\ \hline
Data Processing & NumPy, Pandas, Biopython & Efficient for numerical operations, data manipulation, and bioinformatics tasks. \\ \hline
Machine Learning & Scikit-learn, Imbalanced-learn & Comprehensive libraries for clustering, classification, and handling imbalanced data. \\ \hline
Visualization & Matplotlib, Seaborn & Provide intuitive and customizable plotting capabilities for data analysis. \\ \hline
Database Management & SQLite, PostgreSQL & Lightweight and scalable solutions for storing and querying structured data. \\ \hline
Version Control & Git, GitHub & Essential for collaborative development and version tracking. \\ \hline
Deployment & Flask/FastAPI, Docker & Enable lightweight, scalable, and containerized deployment of the application. \\ \hline
Bioinformatics & Needleman-Wunsch, Smith-Waterman (via Biopython) & Standard algorithms for sequence alignment, implemented efficiently in Biopython. \\ \hline
Computational Resources & HPC, Dedicated Server & Provide the necessary computational power for large-scale data processing and model training. \\ \hline
\end{tabular}
\end{table}


